{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1. Finding words, phrases, names and concepts.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRvpf5atrmKCJcw7SWU3YG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SidharthBhakth/spaCy-NLP/blob/master/1_Finding_words%2C_phrases%2C_names_and_concepts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78xYJ5-ok5mB",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 1: Finding words, phrases, names and concepts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CijQh-fSkpDL",
        "colab_type": "text"
      },
      "source": [
        "## **[Introduction to spaCy](https://www.youtube.com/watch?v=THduWAnG97k&t=16s)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezYwb-uUsMrD",
        "colab_type": "text"
      },
      "source": [
        "#### *Getting Started*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzyzLCXG_iAd",
        "colab_type": "text"
      },
      "source": [
        "> English\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlao4fvLjosE",
        "colab_type": "code",
        "outputId": "ee932b02-32d0-4b5d-e28f-48abddbf497c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import the English language class\n",
        "from spacy.lang.en import English\n",
        "\n",
        "# Create nlp object\n",
        "nlp = English()\n",
        "\n",
        "# Process a text\n",
        "doc = nlp(\"This is a sentence.\")\n",
        "\n",
        "# Print document text\n",
        "print(doc.text)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a sentence.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8ajuDHp_sgL",
        "colab_type": "text"
      },
      "source": [
        "> German"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dINysKaUlqa_",
        "colab_type": "code",
        "outputId": "fefbea3d-7c27-494e-e2db-06896addb88f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import the German language class\n",
        "from spacy.lang.de import German\n",
        "\n",
        "# Create nlp object\n",
        "nlp = German()\n",
        "\n",
        "# Process a text\n",
        "doc = nlp(\"Liebe Grüße!\")\n",
        "\n",
        "# Print document text\n",
        "print(doc.text)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Liebe Grüße!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3besUP8f_vTT",
        "colab_type": "text"
      },
      "source": [
        "> Spanish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH4Xka70rNiD",
        "colab_type": "code",
        "outputId": "d744a84b-0e59-457d-f952-d5e5691ed0af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import Spanish language class\n",
        "from spacy.lang.es import Spanish\n",
        "\n",
        "# Create nlp object\n",
        "nlp = Spanish()\n",
        "\n",
        "# Process a text\n",
        "doc = nlp(\"¿Cómo estás?\")\n",
        "\n",
        "# Print document text\n",
        "print(doc.text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "¿Cómo estás?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvIf7k4oepjj",
        "colab_type": "text"
      },
      "source": [
        "#### *Documents, spans and tokens*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUF4KrDUewBN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b71501ad-8e56-49b1-f566-30365438b683"
      },
      "source": [
        "# Import the English language class\n",
        "from spacy.lang.en import English\n",
        "\n",
        "# Create nlp object\n",
        "nlp = English()\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(\"I like tree kangaroos and narwhals.\")\n",
        "\n",
        "# Select the first token\n",
        "first_token = doc[0]\n",
        "\n",
        "# Print the first token's text\n",
        "print(first_token.text)\n",
        "\n",
        "# A slice of the Doc for \"tree kangaroos\"\n",
        "tree_kangaroos = doc[2:4]\n",
        "print(tree_kangaroos.text)\n",
        "\n",
        "# A slice of the Doc for \"tree kangaroos and narwhals\"\n",
        "tree_kangaroos_and_narwhals = doc[2:6]\n",
        "print(tree_kangaroos_and_narwhals.text)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I\n",
            "tree kangaroos\n",
            "tree kangaroos and narwhals\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cyc5EdsUhSdM",
        "colab_type": "text"
      },
      "source": [
        "#### *Lexical attributes*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVESeoWQgk40",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "adccf852-5e25-4468-8d29-3139f270282e"
      },
      "source": [
        "# Process the text\n",
        "doc = nlp(\"In 1990, more than 60% of people in East Asia were in extreme poverty. \"\n",
        "          \"Now less than 4% are.\")\n",
        "\n",
        "# Iterate over the tokens in the doc\n",
        "for token in doc:\n",
        "  # Check if the token resembles a number\n",
        "  if token.like_num:\n",
        "    # Get the next token in the document\n",
        "    next_token = doc[token.i + 1]\n",
        "    # Check if the next token's text equals \"%\"\n",
        "    if next_token.text == \"%\":\n",
        "      print(\"Percentage found:\", token.text)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage found: 60\n",
            "Percentage found: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnlqZTTbk4ye",
        "colab_type": "text"
      },
      "source": [
        "## **[Statistical Models](https://www.youtube.com/watch?v=THduWAnG97k&t=192s)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHoxq8rumIRT",
        "colab_type": "text"
      },
      "source": [
        "#### *Loading models*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7CG8cNCi2Wy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b20cbd3d-ed5f-4bac-d7ea-5497e7100246"
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Load the \"en_core_web_sm\" model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Process the text\n",
        "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
        "doc = nlp(text)\n",
        "\n",
        "# Print the document text\n",
        "print(doc.text)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71HiIAZ2sz8e",
        "colab_type": "text"
      },
      "source": [
        "#### *Predicting lingusitic annotations*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbvYZ9un__G8",
        "colab_type": "text"
      },
      "source": [
        "> Part-of-Speech tags and dependency labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T117AHu-r1JO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "d9dad0cc-d98a-4742-8763-bc1c85d44dbc"
      },
      "source": [
        "# Get the token text, part-of-speech tag and dependency label\n",
        "for token in doc:\n",
        "  token_text = token.text\n",
        "  token_pos = token.pos_\n",
        "  token_dep = token.dep_\n",
        "  print(f\"{token_text:<12}{token_pos:<10}{token_dep:<10}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It          PRON      nsubj     \n",
            "’s          VERB      punct     \n",
            "official    NOUN      ccomp     \n",
            ":           PUNCT     punct     \n",
            "Apple       PROPN     nsubj     \n",
            "is          AUX       ROOT      \n",
            "the         DET       det       \n",
            "first       ADJ       amod      \n",
            "U.S.        PROPN     nmod      \n",
            "public      ADJ       amod      \n",
            "company     NOUN      attr      \n",
            "to          PART      aux       \n",
            "reach       VERB      relcl     \n",
            "a           DET       det       \n",
            "$           SYM       quantmod  \n",
            "1           NUM       compound  \n",
            "trillion    NUM       nummod    \n",
            "market      NOUN      compound  \n",
            "value       NOUN      dobj      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGQpk_azAMO2",
        "colab_type": "text"
      },
      "source": [
        "> Entity labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijD4rdGPubt4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "687fff40-cabc-4705-8a31-9a2a3e8f0e9c"
      },
      "source": [
        "# Iterate over predicted entities and get the entity text and label\n",
        "for ent in doc.ents:\n",
        "  print(f\"{ent.text:<14}{ent.label_}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple         ORG\n",
            "first         ORDINAL\n",
            "U.S.          GPE\n",
            "$1 trillion   MONEY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhyXdpjXvhJY",
        "colab_type": "text"
      },
      "source": [
        "#### *Predicting named entities in context*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0go0mhovpnt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c600bf48-763a-4a68-9d57-3ccd3c51af2c"
      },
      "source": [
        "# Process the text\n",
        "text = \"Upcoming iPhone X release date leaked as Apple reveals pre-orders\"\n",
        "doc = nlp(text)\n",
        "\n",
        "# Iterate over predicted entities and get the entity text and label\n",
        "for ent in doc.ents:\n",
        "  print(f\"{ent.text:<14}{ent.label_}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple         ORG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVKxXa09wibb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a0d74f3-b78a-4e21-f6f3-b8fedfc0b192"
      },
      "source": [
        "# Get the span for \"iPhone X\"\n",
        "iphone_x = doc[1:3]\n",
        "\n",
        "# Print the span text\n",
        "print(\"Missing entity:\", iphone_x.text)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Missing entity: iPhone X\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hThaxKhdyCW_",
        "colab_type": "text"
      },
      "source": [
        "## **[Rule-based matching](https://www.youtube.com/watch?v=THduWAnG97k&t=431s)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51rRAx3A-e4V",
        "colab_type": "text"
      },
      "source": [
        "#### *Using the Matcher*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkrDV82ZyapI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1db1adba-402e-4f85-8a3f-50e59b50615f"
      },
      "source": [
        "# Import the matcher\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Intialize matcher with shared vocabulary\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Create  a pattern matching two tokens: \"iPhone\" and \"X\"\n",
        "pattern = [{\"TEXT\":\"iPhone\"}, {\"TEXT\":\"X\"}]\n",
        "\n",
        "# Add pattern to matcher\n",
        "matcher.add(\"IPHONE_X_PATTERN\", None, pattern)\n",
        "\n",
        "# Use the matcher on the doc\n",
        "matches = matcher(doc)\n",
        "print(\"Matches found:\", [ doc[start:end].text for match_id, start, end in matches ])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matches found: ['iPhone X']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHrTY8xV-kaI",
        "colab_type": "text"
      },
      "source": [
        "#### *Writing matching patterns*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZEMEKDr_Qm1",
        "colab_type": "text"
      },
      "source": [
        "> Write **one** pattern that only matches mentions of the full iOS versions: “iOS 7”, “iOS 11” and “iOS 10”.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEgAcmr24oFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "65b848b6-ab8d-411b-bb47-b75c61a19e3f"
      },
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "doc = nlp(\"After making the iOS update you won't notice a radical system-wide \"\n",
        "          \"redesign: nothing like the aesthetic upheaval we got with iOS 7. Most of \"\n",
        "          \"iOS 11's furniture remains the same as in iOS 10. But you will discover \"\n",
        "          \"some tweaks once you delve a little deeper.\")\n",
        "\n",
        "# Write a pattern for full iOS versions\n",
        "pattern = [{\"TEXT\":\"iOS\"}, {\"IS_DIGIT\":True}]\n",
        "\n",
        "# Add the pattern to the matcher\n",
        "matcher.add(\"IOS_VERSION_PATTERN\", None, pattern)\n",
        "\n",
        "# Apply the matcher to the doc\n",
        "matches = matcher(doc)\n",
        "print(\"Total matches found:\", len(matches))\n",
        "\n",
        "# Iterate over the matches and print the span text\n",
        "for match_id, start, end in matches:\n",
        "  print(\"Match found:\", doc[start:end].text)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total matches found: 3\n",
            "Match found: iOS 7\n",
            "Match found: iOS 11\n",
            "Match found: iOS 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaRC6LO8DA13",
        "colab_type": "text"
      },
      "source": [
        "> Write **one** pattern that only matches forms of “download” (tokens with the lemma “download”), followed by a token with the part-of-speech tag \"PROPN\" (proper noun)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzTq10DHDH7Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "a7cc58fe-8e7a-4496-b541-3c5249cbba5b"
      },
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "doc = nlp(\"i downloaded Fortnite on my laptop and can't open the game at all. Help? \"\n",
        "          \"so when I was downloading Minecraft, I got the Windows version where it \"\n",
        "          \"is the '.zip' folder and I used the default program to unpack it... do \"\n",
        "          \"I also need to download Winzip?\")\n",
        "\n",
        "# Write a pattern that matches a form of \"download\" plus proper noun\n",
        "pattern = [{\"LEMMA\":\"download\"}, {\"POS\":\"PROPN\"}]\n",
        "\n",
        "# Add the pattern to the matcher\n",
        "matcher.add(\"DOWNLOAD_THINGS_PATTERN\", None, pattern)\n",
        "\n",
        "# Apply the matcher to the doc\n",
        "matches = matcher(doc)\n",
        "print(\"Total matches found:\", len(matches))\n",
        "\n",
        "# Iterate over the matches and print the span text\n",
        "for match_id, start, end in matches:\n",
        "  print(\"Match found:\", doc[start:end].text)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total matches found: 3\n",
            "Match found: downloaded Fortnite\n",
            "Match found: downloading Minecraft\n",
            "Match found: download Winzip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R760b9xTD8tx",
        "colab_type": "text"
      },
      "source": [
        "> Write **one** pattern that matches adjectives (\"ADJ\") followed by one or two \"NOUN\"s (one noun and one optional noun)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U3oNDf1EIHu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "0eaeccc4-e02f-424d-c7e0-6c9149020a7c"
      },
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "doc = nlp(\"Features of the app include a beautiful design, smart search, automatic \"\n",
        "          \"labels and optional voice responses.\")\n",
        "\n",
        "# Write a pattern for adjective plus one or two nouns\n",
        "pattern = [{\"POS\":\"ADJ\"}, {\"POS\":\"NOUN\"}, {\"POS\":\"NOUN\", \"OP\":\"?\"}]\n",
        "\n",
        "# Add the pattern to the matcher\n",
        "matcher.add(\"DOWNLOAD_THINGS_PATTERN\", None, pattern)\n",
        "\n",
        "# Apply the matcher to the doc\n",
        "matches = matcher(doc)\n",
        "print(\"Total matches found:\", len(matches))\n",
        "\n",
        "# Iterate over the matches and print the span text\n",
        "for match_id, start, end in matches:\n",
        "  print(\"Match found:\", doc[start:end].text)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total matches found: 5\n",
            "Match found: beautiful design\n",
            "Match found: smart search\n",
            "Match found: automatic labels\n",
            "Match found: optional voice\n",
            "Match found: optional voice responses\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}